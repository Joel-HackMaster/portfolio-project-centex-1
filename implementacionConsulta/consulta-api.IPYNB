{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c771932a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"SessionCentexETL\") \\\n",
    "    .master(\"local[4]\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", 4) \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .config(\"spark.jars\", \"C:\\\\jars\\\\mssql-jdbc-12.10.0.jre11.jar\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "248a84e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "\n",
    "jdbc_url = f\"jdbc:sqlserver://{os.getenv('DB_HOST')}:{os.getenv('DB_PORT')};databaseName={os.getenv('DB_NAME')};encrypt=true;trustServerCertificate=true\"\n",
    "properties = {\n",
    "    \"user\": os.getenv('DB_USER'),\n",
    "    \"password\": os.getenv('DB_PASSWORD'),\n",
    "    \"driver\": \"com.microsoft.sqlserver.jdbc.SQLServerDriver\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "68c1c201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total distinct 'ID_Agenda' in empresas: 60\n",
      "+--------------+\n",
      "|ID_Agenda     |\n",
      "+--------------+\n",
      "|03882991      |\n",
      "|05343586      |\n",
      "|06070544      |\n",
      "|07247883000269|\n",
      "|10004191604   |\n",
      "|10085296391   |\n",
      "|10096359701   |\n",
      "|10252120      |\n",
      "|10726397355   |\n",
      "|15429137      |\n",
      "|15982454      |\n",
      "|18171528      |\n",
      "|20100041953   |\n",
      "|20100049181   |\n",
      "|20100050359   |\n",
      "|20100365341   |\n",
      "|20101158927   |\n",
      "|20101520898   |\n",
      "|20108811375   |\n",
      "|20119546851   |\n",
      "|20122621830   |\n",
      "|20127765279   |\n",
      "|20131312955   |\n",
      "|20251549835   |\n",
      "|20380280907   |\n",
      "|20381235051   |\n",
      "|20390900407   |\n",
      "|20404698428   |\n",
      "|20448661378   |\n",
      "|20455823880   |\n",
      "|20469653707   |\n",
      "|20471195881   |\n",
      "|20481828792   |\n",
      "|20502007018   |\n",
      "|20505018509   |\n",
      "|20507379002   |\n",
      "|20507661441   |\n",
      "|20520543466   |\n",
      "|20523634110   |\n",
      "|20536124404   |\n",
      "|20536563823   |\n",
      "|20537746956   |\n",
      "|20539528441   |\n",
      "|20539666917   |\n",
      "|20543602664   |\n",
      "|20544466080   |\n",
      "|20544488059   |\n",
      "|20547025319   |\n",
      "|20547254776   |\n",
      "|20548704261   |\n",
      "|20549068201   |\n",
      "|20550372640   |\n",
      "|20550688442   |\n",
      "|20550772079   |\n",
      "|20551093035   |\n",
      "|20552016506   |\n",
      "|20553829306   |\n",
      "|20564352471   |\n",
      "|20600283015   |\n",
      "|20600593685   |\n",
      "+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query_pa = \"(select * from Doc_Compra) AS query_pa\"\n",
    "df_empresas = spark.read.jdbc(url=jdbc_url, table=query_pa, properties=properties)\n",
    "df_ruc = df_empresas.select(\"ID_Agenda\").distinct().limit(60)\n",
    "\n",
    "print(f\"Total distinct 'ID_Agenda' in empresas: {df_ruc.count()}\")\n",
    "\n",
    "df_ruc.show(df_ruc.count(), truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a81c1980",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def consulta_api(ruc):\n",
    "    url = f\"http://127.0.0.1:8000/v2/sunat/ruc/{ruc}\"\n",
    "    try:\n",
    "        response = requests.get(url, timeout=5)\n",
    "        if response.status_code == 200:\n",
    "            return response.json()\n",
    "        else:\n",
    "            return {\"error\": f\"Status {response.status_code}\"}\n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "resultados = [consulta_api(row['ID_Agenda']) for row in df_ruc.collect()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "92f159e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de filas en resultados_limpios: 10\n",
      "Ejemplo de resultados crudos:\n",
      "{'razonSocial': 'SOUTHERN PERU COPPER CORPORATION, SUCURSAL DEL PERÚ', 'tipoDocumento': '6', 'numeroDocumento': '20100147514', 'estado': 'ACTIVO', 'condicion': 'HABIDO', 'direccion': 'AV. CAMINOS DEL INCA NRO 171 URB. CHACARILLA DEL ESTANQUE ', 'ubigeo': '150140', 'viaTipo': 'AV.', 'viaNombre': 'CAMINOS DEL INCA'}\n",
      "{'razonSocial': 'COMPAÑIA MINERA ANTAPACCAY S.A.', 'tipoDocumento': '6', 'numeroDocumento': '20114915026', 'estado': 'ACTIVO', 'condicion': 'HABIDO', 'direccion': 'CAMPAMENTO MINERO TINTAYA NRO SN CAMPAMENTO MINERO TINTAYA ', 'ubigeo': '080801', 'viaTipo': '-', 'viaNombre': 'CAMPAMENTO MINERO TINTAYA'}\n",
      "{'razonSocial': 'CAL & CEMENTO SUR S.A.', 'tipoDocumento': '6', 'numeroDocumento': '20115039262', 'estado': 'ACTIVO', 'condicion': 'HABIDO', 'direccion': 'CAR. JULIACA-PUNO HACIENDA YUNGURA KM. 11 ', 'ubigeo': '211104', 'viaTipo': 'CAR.', 'viaNombre': 'JULIACA-PUNO'}\n",
      "{'razonSocial': 'SUPERINTENDENCIA NACIONAL DE ADUANAS Y DE ADMINISTRACION TRIBUTARIA - SUNAT', 'tipoDocumento': '6', 'numeroDocumento': '20131312955', 'estado': 'ACTIVO', 'condicion': 'HABIDO', 'direccion': 'AV. GARCILASO DE LA VEGA NRO 1472 ', 'ubigeo': '150101', 'viaTipo': 'AV.', 'viaNombre': 'GARCILASO DE LA VEGA'}\n",
      "{'razonSocial': 'PONTIFICIA UNIVERSIDAD CATOLICA DEL PERU', 'tipoDocumento': '6', 'numeroDocumento': '20155945860', 'estado': 'ACTIVO', 'condicion': 'HABIDO', 'direccion': 'AV. UNIVERSITARIA NRO 1801 URB. PANDO ', 'ubigeo': '150136', 'viaTipo': 'AV.', 'viaNombre': 'UNIVERSITARIA'}\n",
      "{'razonSocial': 'UNIVERSIDAD NACIONAL DE SAN ANTONIO ABAD DEL CUSCO', 'tipoDocumento': '6', 'numeroDocumento': '20172474501', 'estado': 'ACTIVO', 'condicion': 'HABIDO', 'direccion': 'AV. DE LA CULTURA NRO 733 ', 'ubigeo': '080101', 'viaTipo': 'AV.', 'viaNombre': 'DE LA CULTURA'}\n",
      "{'razonSocial': 'COMPANIA MINERA ARES S.A.C.', 'tipoDocumento': '6', 'numeroDocumento': '20192779333', 'estado': 'ACTIVO', 'condicion': 'HABIDO', 'direccion': 'CAL. LA COLONIA NRO 180 URB. EL VIVERO ', 'ubigeo': '150140', 'viaTipo': 'CAL.', 'viaNombre': 'LA COLONIA'}\n",
      "{'razonSocial': 'NEXA RESOURCES CAJAMARQUILLA S.A.', 'tipoDocumento': '6', 'numeroDocumento': '20261677955', 'estado': 'ACTIVO', 'condicion': 'HABIDO', 'direccion': 'CAR. CAR. CENTRAL NRO 9.5 CAJAMARQUILLA ', 'ubigeo': '150118', 'viaTipo': 'CAR.', 'viaNombre': 'CAR. CENTRAL'}\n",
      "{'razonSocial': 'EMBAJADA DE LOS ESTADOS UNIDOS AMERICA', 'tipoDocumento': '6', 'numeroDocumento': '20293588776', 'estado': 'ACTIVO', 'condicion': 'HABIDO', 'direccion': 'AV. LA ENCALADA NRO C-17 ', 'ubigeo': '150140', 'viaTipo': 'AV.', 'viaNombre': 'LA ENCALADA'}\n",
      "{'razonSocial': 'CEMENTOS PACASMAYO S.A.A.', 'tipoDocumento': '6', 'numeroDocumento': '20419387658', 'estado': 'ACTIVO', 'condicion': 'HABIDO', 'direccion': 'CAL. LA COLONIA NRO 150 URB. EL VIVERO ', 'ubigeo': '150140', 'viaTipo': 'CAL.', 'viaNombre': 'LA COLONIA'}\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType\n",
    "\n",
    "campos_resultados = [\"razonSocial\", \"tipoDocumento\", \"numeroDocumento\", \"estado\", \"condicion\", \"direccion\", \"ubigeo\", \"viaTipo\", \"viaNombre\"]\n",
    "\n",
    "schema = StructType([StructField(campo, StringType(), True) for campo in campos_resultados])\n",
    "\n",
    "resultados_limpios = [\n",
    "    {campo: resultado.get(campo, None) for campo in campos_resultados}\n",
    "    for resultado in resultados if isinstance(resultado, dict)\n",
    "]\n",
    "\n",
    "print(\"Cantidad de filas en resultados_limpios:\", len(resultados_limpios))\n",
    "if len(resultados_limpios) == 0:\n",
    "    print(\"¡La lista está vacía! No se puede crear un DataFrame vacío en Spark con esquema inferido.\")\n",
    "\n",
    "print(\"Ejemplo de resultados crudos:\")\n",
    "for r in resultados_limpios:\n",
    "    print(r)\n",
    "\n",
    "#resultados_limpios = [r for r in resultados_limpios if any(v is not None for v in r.values())]\n",
    "\n",
    "#df_ruc_resultados = spark.createDataFrame(resultados_limpios, schema=schema)\n",
    "#df_ruc_resultados.coalesce(1).write.mode(\"overwrite\").option(\"header\", True).csv(\"DevueltosCSV/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a8bb0158",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_pd = pd.DataFrame(resultados_limpios)\n",
    "\n",
    "df_pd.to_csv(\"DevueltosCSV/resultados.csv\", index=False, encoding='utf-8-sig')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
